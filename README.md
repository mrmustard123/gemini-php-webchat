# Gemini PHP WebChat

A simple **web-based chat interface** built with **HTML, TailwindCSS, JavaScript, and PHP**.  
It provides a lightweight frontend for chat messages and a PHP backend that handles user input, stores chat sessions in JSON, and simulates AI responses.

---

## âœ¨  Features

- Clean and minimal **chat UI** (bubbles for user and assistant).
- **Scrollable conversation window** with automatic scroll to the latest message.
- **Persistent chat sessions** saved in `chat_session.json`.
- **AJAX communication** between frontend (HTML/JS) and backend (PHP).
- Ready to be extended with **LLM APIs** (e.g., Gemini, OpenAI).

---

## ðŸ“‚ Project Structure

/project-root

Â¦
+-- index.php # Main chat UI (HTML + Tailwind + JS)

+-- chat.php # PHP endpoint (receives messages, updates session)

+-- chat_session.json # Stores conversation history

+-- README.md # Project documentation

---

## âš™ï¸ Requirements

- PHP **>= 8.0** (tested with PHP 8.1.0)
- A local server like **WampServer**, **XAMPP**, or **PHP built-in server**
- (Optional) An IDE like **NetBeans** with XDebug for debugging

---

## ðŸš€ Setup & Run

1. Clone or copy the project into your PHP server directory (`www` or `htdocs`).
2. Start your local server (Wamp, XAMPP, or `php -S localhost:8000`).
3. Open the chat in your browser:
http://localhost/index.php

4. Start chatting! Messages are sent to the backend (`chat.php`) and stored in `chat_session.json`.

---

## ðŸ“Œ How It Works

1. **Frontend (`index.php`)**  
- Displays a chat UI with message bubbles.  
- Captures user input and sends it via `fetch()` (AJAX POST request) to `chat.php`.  

2. **Backend (`chat.php`)**  
- Reads the JSON body using:
  ```php
     $rawInput = file_get_contents('php://input');
  ```
- Appends the user message to `chat_session.json`.  
- Generates a placeholder assistant response (can be replaced with API call).  
- Returns the assistant message as JSON.

3. **Persistence**  
- Conversation history is saved in `chat_session.json`.  
- On each refresh, past messages are loaded and displayed.

---

## ðŸ“Œ Example

**User:** Hello Gemini!  
**Assistant:** (Simulated response) Hi there! This is a placeholder response.

---

## ðŸ”® Next Steps

- Connect to **Gemini API** (Google) or **OpenAI API** to generate real AI responses.  
- Add **user authentication** for multiple chat sessions.  
- Improve **UI styling** and add message timestamps.  
- Deploy to a real server or cloud hosting.

---

## ðŸ“œ License

This project is provided under the **MIT License**.  
Feel free to use, modify, and distribute it.

---

